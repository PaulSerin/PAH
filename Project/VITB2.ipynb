{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINETUNING da la derniere couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 16:03:44.063703: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-27 16:03:45.193078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-27 16:03:45.508177: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-27 16:03:45.593904: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-27 16:03:46.378959: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-27 16:03:49.180109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [03:50<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss moyenne: 0.1513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [03:47<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Loss moyenne: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [03:47<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Loss moyenne: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:   1%|█▍                                                                                                                      | 9/782 [00:02<03:45,  3.44it/s]"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from torch import nn, optim\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch.utils.data import DataLoader, random_split\n",
    "# from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "\n",
    "# # Fonction de collate personnalisée\n",
    "# def custom_collate_fn(batch):\n",
    "#     images, labels = zip(*batch)\n",
    "#     return list(images), torch.tensor(labels)\n",
    "\n",
    "# # Fonction pour obtenir la taille du modèle\n",
    "# def get_model_size(model, temp_path=\"temp_model.pth\"):\n",
    "#     torch.save(model.state_dict(), temp_path)\n",
    "#     size_mb = os.path.getsize(temp_path) / 1e6\n",
    "#     os.remove(temp_path)\n",
    "#     return size_mb\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Dataset CIFAR-10\n",
    "# transform = transforms.Resize((224, 224))\n",
    "# train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# test_dataset  = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# # Réduire le train set\n",
    "# train_size = int(0.5 * len(train_dataset))\n",
    "# train_subset, _ = random_split(train_dataset, [train_size, len(train_dataset) - train_size])\n",
    "\n",
    "# train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "# test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# # Charger ViT\n",
    "# processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "# model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "# model.classifier = nn.Linear(model.config.hidden_size, 10)  # 10 classes pour CIFAR-10\n",
    "# model.to(device)\n",
    "\n",
    "# # Optimiseur et loss\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Entraînement\n",
    "# epochs = 5\n",
    "# losses = []\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "#         inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(**inputs)\n",
    "#         loss = criterion(outputs.logits, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     epoch_loss = running_loss / len(train_loader)\n",
    "#     losses.append(epoch_loss)\n",
    "#     print(f\"Epoch {epoch+1}/{epochs} - Loss moyenne: {epoch_loss:.4f}\")\n",
    "\n",
    "# # Évaluation\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in tqdm(test_loader, desc=\"Evaluation\"):\n",
    "#         inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "#         outputs = model(**inputs)\n",
    "#         preds = outputs.logits.argmax(dim=1)\n",
    "#         correct += (preds == labels.to(device)).sum().item()\n",
    "#         total += labels.size(0)\n",
    "\n",
    "# accuracy = 100 * correct / total\n",
    "# print(f\"\\nAccuracy sur CIFAR-10 : {accuracy:.2f}%\")\n",
    "\n",
    "# # Plot des pertes\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.plot(range(1, len(losses)+1), losses, marker='o')\n",
    "# plt.title(\"Courbe de perte durant le fine-tuning de la tête\")\n",
    "# plt.xlabel(\"Époch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(save_path, \"loss_curve.png\"))  # sauvegarde en image\n",
    "# plt.show()\n",
    "\n",
    "# # Taille du modèle\n",
    "# model_size = get_model_size(model)\n",
    "# print(f\"Taille du modèle : {model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrer le modele head finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"saved_models/vit_head_finetuned_full.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réutiliser le modele depuis save dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/11424982/ipykernel_2334467/3874483511.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"saved_models/vit_head_finetuned_full.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTSdpaAttention(\n",
       "            (attention): ViTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Recharger l'architecture du modèle\n",
    "# model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "# model.classifier = torch.nn.Linear(model.config.hidden_size, 10)  # Adapter à CIFAR-10\n",
    "\n",
    "# # Charger les poids\n",
    "# state_dict = torch.load(\"saved_models/vit_head_finetuned_full.pth\")\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taille du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du modèle : 343.31 MB\n"
     ]
    }
   ],
   "source": [
    "# # Fonction pour afficher la taille\n",
    "# def get_model_size(model, temp_path=\"temp_model.pth\"):\n",
    "#     torch.save(model.state_dict(), temp_path)\n",
    "#     size_mb = os.path.getsize(temp_path) / 1e6\n",
    "#     os.remove(temp_path)\n",
    "#     return size_mb\n",
    "\n",
    "# # Affichage\n",
    "# model_size = get_model_size(model)\n",
    "# print(f\"Taille du modèle : {model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINETUNING des 3 dernieres couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 10:57:05.119159: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-28 10:57:07.611838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-28 10:57:08.053018: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-28 10:57:08.230540: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-28 10:57:10.390939: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-28 10:57:13.715030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:02<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss moyenne: 0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:01<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Loss moyenne: 0.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:00<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Loss moyenne: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:00<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Loss moyenne: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:01<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Loss moyenne: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:39<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sur CIFAR-10: 97.63%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du modèle sauvegardé : 343.31 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Fonction de collate personnalisée\n",
    "def custom_collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    return list(images), torch.tensor(labels)\n",
    "\n",
    "# Fonction utilitaire pour mesurer la taille du modèle\n",
    "def get_model_size(model, temp_path=\"temp_model.pth\"):\n",
    "    torch.save(model.state_dict(), temp_path)\n",
    "    size_mb = os.path.getsize(temp_path) / 1e6\n",
    "    os.remove(temp_path)\n",
    "    return size_mb\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset CIFAR-10\n",
    "transform = transforms.Resize((224, 224))\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Réduction du dataset\n",
    "total_train = len(train_dataset)\n",
    "train_size = int(0.5 * total_train)\n",
    "train_subset, _ = random_split(train_dataset, [train_size, total_train - train_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Modèle ViT\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "model.classifier = nn.Linear(model.config.hidden_size, 10)\n",
    "\n",
    "# Geler le backbone\n",
    "for param in model.vit.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze les 2 derniers blocs\n",
    "for layer in model.vit.encoder.layer[-2:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ➤ Enregistrement des pertes\n",
    "losses = []\n",
    "\n",
    "# Entraînement\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss moyenne: {epoch_loss:.4f}\")\n",
    "\n",
    "# Évaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Evaluation\"):\n",
    "        inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "        preds = outputs.logits.argmax(dim=1)\n",
    "        correct += (preds == labels.to(device)).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy sur CIFAR-10: {accuracy:.2f}%\")\n",
    "\n",
    "# ➤ Afficher la courbe de loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(losses)+1), losses, marker='o')\n",
    "plt.title(\"Courbe de perte durant l'entraînement\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "size_mb = get_model_size(model)\n",
    "print(f\"Taille du modèle sauvegardé : {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrer le modele head finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle et processor sauvegardés dans : saved_models/vit_finetuned_hf\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "\n",
    "# Chemin de sauvegarde\n",
    "save_path = \"saved_models/vit_finetuned_hf\"\n",
    "\n",
    "# Sauvegarde du modèle complet\n",
    "model.save_pretrained(save_path)\n",
    "\n",
    "# Sauvegarde du processor\n",
    "processor.save_pretrained(save_path)\n",
    "\n",
    "print(f\"Modèle et processor sauvegardés dans : {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUANTIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at saved_models/vit_finetuned_hf and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([10]) in the checkpoint and torch.Size([1000]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([10, 768]) in the checkpoint and torch.Size([1000, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Évaluation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [02:45<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistiques du modèle quantifié :\n",
      "Taille mémoire du modèle : 88.53 MB\n",
      "Accuracy sur CIFAR-10 : 6.83%\n",
      "Temps moyen d'inférence par batch : 516.01 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import io\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------\n",
    "# Fonction : taille mémoire du modèle\n",
    "# -------------------------------\n",
    "def get_model_size_in_memory(model):\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(model.state_dict(), buffer)\n",
    "    return buffer.getbuffer().nbytes / 1e6  # en MB\n",
    "\n",
    "# -------------------------------\n",
    "# Fonction d’évaluation\n",
    "# -------------------------------\n",
    "def evaluate(model, processor, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    inference_times = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Évaluation\"):\n",
    "            start = time.time()\n",
    "\n",
    "            inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "\n",
    "            inference_times.append(time.time() - start)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    avg_inf_time = sum(inference_times) / len(inference_times)\n",
    "    return acc, avg_inf_time\n",
    "\n",
    "# -------------------------------\n",
    "# Dataset CIFAR-10\n",
    "# -------------------------------\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "transform = transforms.Resize((224, 224))\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    return list(images), torch.tensor(labels)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# -------------------------------\n",
    "# Recharger le modèle fine-tuné\n",
    "# -------------------------------\n",
    "model_path = \"saved_models/vit_finetuned_hf\"\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_path,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.classifier = torch.nn.Linear(model.config.hidden_size, 10)\n",
    "\n",
    "# -------------------------------\n",
    "# Quantization dynamique propre\n",
    "# -------------------------------\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Évaluation sur CPU\n",
    "# -------------------------------\n",
    "device = torch.device(\"cpu\")\n",
    "quantized_model.to(device)\n",
    "\n",
    "quantized_size = get_model_size_in_memory(quantized_model)\n",
    "q_acc, q_time = evaluate(quantized_model, processor, test_loader, device)\n",
    "\n",
    "# -------------------------------\n",
    "# Affichage des résultats\n",
    "# -------------------------------\n",
    "print(\"\\nStatistiques du modèle quantifié :\")\n",
    "print(f\"Taille mémoire du modèle : {quantized_size:.2f} MB\")\n",
    "print(f\"Accuracy sur CIFAR-10 : {q_acc:.2f}%\")\n",
    "print(f\"Temps moyen d'inférence par batch : {q_time*1000:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "\n",
      "==> Pruning 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Pruning 30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Pruning 50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Pruning 70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Pruning 90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résumé des modèles prunés :\n",
      "Pruning    Sparsity   Taille (MB)    Accuracy   Inférence (ms) \n",
      "10%        10.00%     683.10         7.45%      517.92         \n",
      "30%        30.00%     683.10         6.80%      508.70         \n",
      "50%        50.00%     683.10         10.00%     519.60         \n",
      "70%        70.00%     683.10         10.00%     504.56         \n",
      "90%        90.00%     683.10         10.00%     506.01         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import time\n",
    "import io\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTImageProcessor\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "# ------------------------------\n",
    "# Fonction : taille en mémoire du modèle\n",
    "# ------------------------------\n",
    "def get_model_size_in_memory(model):\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(model.state_dict(), buffer)\n",
    "    size_mb = buffer.getbuffer().nbytes / 1e6\n",
    "    return size_mb\n",
    "\n",
    "# ------------------------------\n",
    "# Fonction d'évaluation\n",
    "# ------------------------------\n",
    "def evaluate(model, processor, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    inference_times = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Évaluation\", leave=False):\n",
    "            start = time.time()\n",
    "\n",
    "            inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "\n",
    "            inference_times.append(time.time() - start)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_inference_time = sum(inference_times) / len(inference_times)\n",
    "    return accuracy, avg_inference_time\n",
    "\n",
    "# ------------------------------\n",
    "# Fonction de pruning global\n",
    "# ------------------------------\n",
    "def apply_global_pruning(model, amount):\n",
    "    parameters_to_prune = []\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            parameters_to_prune.append((module, 'weight'))\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=amount,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ------------------------------\n",
    "# Calcul de la sparsité\n",
    "# ------------------------------\n",
    "def compute_sparsity(model):\n",
    "    total_zeros = 0\n",
    "    total_params = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            w = module.weight\n",
    "            total_zeros += torch.sum(w == 0).item()\n",
    "            total_params += w.numel()\n",
    "    sparsity = 100.0 * total_zeros / total_params if total_params > 0 else 0.0\n",
    "    return sparsity\n",
    "\n",
    "# ------------------------------\n",
    "# Préparation dataset\n",
    "# ------------------------------\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "transform = transforms.Resize((224, 224))\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    return list(images), torch.tensor(labels)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# ------------------------------\n",
    "# Ton modèle `model` doit déjà exister en mémoire (fine-tuné)\n",
    "# ------------------------------\n",
    "assert 'model' in globals(), \"Le modèle `model` doit être défini en mémoire avant ce script.\"\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "pruning_levels = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "results = []\n",
    "\n",
    "for amount in pruning_levels:\n",
    "    print(f\"\\n==> Pruning {int(amount * 100)}%\")\n",
    "\n",
    "    pruned_model = deepcopy(model)\n",
    "    pruned_model = apply_global_pruning(pruned_model, amount)\n",
    "    pruned_model.to(device)\n",
    "\n",
    "    sparsity = compute_sparsity(pruned_model)\n",
    "    size_mb = get_model_size_in_memory(pruned_model)\n",
    "    acc, inf_time = evaluate(pruned_model, processor, test_loader, device)\n",
    "\n",
    "    results.append({\n",
    "        \"pruning\": f\"{int(amount * 100)}%\",\n",
    "        \"sparsity\": f\"{sparsity:.2f}%\",\n",
    "        \"size_mb\": f\"{size_mb:.2f}\",\n",
    "        \"accuracy\": f\"{acc:.2f}%\",\n",
    "        \"inference_time_ms\": f\"{inf_time * 1000:.2f}\"\n",
    "    })\n",
    "\n",
    "# ------------------------------\n",
    "# Résumé final\n",
    "# ------------------------------\n",
    "print(\"\\nRésumé des modèles prunés :\")\n",
    "print(f\"{'Pruning':<10} {'Sparsity':<10} {'Taille (MB)':<14} {'Accuracy':<10} {'Inférence (ms)':<15}\")\n",
    "for r in results:\n",
    "    print(f\"{r['pruning']:<10} {r['sparsity']:<10} {r['size_mb']:<14} {r['accuracy']:<10} {r['inference_time_ms']:<15}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "mypython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
